{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes Error Rate Estimation Tutorial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.datasets as tfds\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, InputLayer\n",
    "from tensorflow.nn import relu\n",
    "\n",
    "from daml.datasets import DamlDataset\n",
    "from daml.metrics.ber import BER_MST\n",
    "\n",
    "tf.keras.utils.set_random_seed(408)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading in data\n",
    "\n",
    "Let's start by loading in tensorflow's mnist dataset, \n",
    "then we will examine it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the mnist dataset from tensorflow datasets\n",
    "(images, labels), (test_images, test_labels) = tfds.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training samples: \", len(images))\n",
    "print(\"Image shape:\", images[0].shape)\n",
    "print(\"Label counts: \", np.unique(labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To highlight the effects of modifying the dataset on its Bayes Error Rate,\n",
    "we will only include a subset of 9,000 images and their labels for digits 1, 4, and 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_split = dict()\n",
    "labels_split = dict()\n",
    "\n",
    "# Keep only 1, 4, and 9\n",
    "for label in (1, 4, 9):\n",
    "    subset_indices = np.where(labels == label)\n",
    "    images_split[label] = images[subset_indices][:3000]\n",
    "    labels_split[label] = labels[subset_indices][:3000]\n",
    "\n",
    "images_subset = np.concatenate(list(images_split.values()))\n",
    "labels_subset = np.concatenate(list(labels_split.values()))\n",
    "print(images_subset.shape)\n",
    "print(np.unique(labels_subset, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have taken a subset of the data that is only the digits 1, 4, and 9.\n",
    "The BER estimate requires 1 dimension, so we flatten the images during this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images\n",
    "images_flattened = images_subset.reshape((images_subset.shape[0], -1))\n",
    "print(\"Dataset shape:\", images_flattened.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 9,000 flattened images of size 784.\n",
    "\n",
    "Let's wrap the images and labels in a DamlDataset and move on to evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap images and labels in to a typed DamlDataset\n",
    "dataset = DamlDataset(images_flattened, labels_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "Suppose we would like to build a classifier that differentiates between the handwritten digits 1, 4, and 9 with predetermined accuracy requirement of 99%.\n",
    "\n",
    "We will use BER to check the feasibility of the task.\n",
    "As the images are small, we can simple use the flattened raw pixel intensities to calculate BER (no embedding necessary).\n",
    "*Note*: This will not be the case in general. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BER metric\n",
    "metric = BER_MST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the BER metric for the MNIST data with digits 1, 4, 9.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# One minus the value of this metric gives our estimate of the upper bound on accuracy.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m base_ber \u001b[38;5;241m=\u001b[39m \u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/daml/src/daml/_internal/metrics/aria/ber.py:86\u001b[0m, in \u001b[0;36m_MultiClassBer.evaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     83\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m X \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m permute_to_numpy(X)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(embeddings, np\u001b[38;5;241m.\u001b[39mndarray)\n\u001b[0;32m---> 86\u001b[0m ber, ber_lower \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_multiclass_ber\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BEROutput(ber\u001b[38;5;241m=\u001b[39mber, ber_lower\u001b[38;5;241m=\u001b[39mber_lower)\n",
      "File \u001b[0;32m/workspaces/daml/src/daml/_internal/metrics/aria/ber.py:132\u001b[0m, in \u001b[0;36mMultiClassBerMST._multiclass_ber\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    130\u001b[0m dense_eudist \u001b[38;5;241m=\u001b[39m squareform(pdist(X)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-4\u001b[39m\n\u001b[1;32m    131\u001b[0m eudist_csr \u001b[38;5;241m=\u001b[39m csr_matrix(dense_eudist)\n\u001b[0;32m--> 132\u001b[0m tree \u001b[38;5;241m=\u001b[39m coo_matrix(\u001b[43mminimum_spanning_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43meudist_csr\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28msum\u001b[39m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum([y[tree\u001b[38;5;241m.\u001b[39mrow[i]] \u001b[38;5;241m!=\u001b[39m y[tree\u001b[38;5;241m.\u001b[39mcol[i]] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)])\n\u001b[1;32m    134\u001b[0m deltas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m N)\n",
      "File \u001b[0;32m_min_spanning_tree.pyx:101\u001b[0m, in \u001b[0;36mscipy.sparse.csgraph._min_spanning_tree.minimum_spanning_tree\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36margsort\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/numpy/core/fromnumeric.py:1146\u001b[0m, in \u001b[0;36margsort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_argsort_dispatcher)\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21margsort\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;124;03m    Returns the indices that would sort an array.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \n\u001b[1;32m   1145\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margsort\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate the BER metric for the MNIST data with digits 1, 4, 9.\n",
    "# One minus the value of this metric gives our estimate of the upper bound on accuracy.\n",
    "base_ber = metric.evaluate(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The bayes error rate estimation:\", base_ber.ber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimate of the maximum achievable accuracy is one minus the BER estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The maximum achievable accuracy:\", (1 - base_ber.ber) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results\n",
    "The maximum achievable accuracy on a dataset of 1, 4, and 9 is about 98.1%.\n",
    "This *does not* meet our requirement of 99% accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modify dataset classification\n",
    "To address insufficient accuracy, lets modify the dataset to classify an image as \"1\" or \"Not a 1\".\n",
    "By combining classes, we can hopefully achieve the desired level of attainable accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a binary mask showing if the current label == 1 that can be used as the new labels\n",
    "labels_merged = labels_subset == 1\n",
    "print(\"New label counts:\", np.unique(labels_merged, return_counts=True))\n",
    "\n",
    "# Update the DamlDataset with merged labels\n",
    "dataset.labels = labels_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the BER metric for the MNIST data with digits 1, 4, and 9, but combining classes 4 & 9.\n",
    "new_ber = metric.evaluate(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The bayes error rate estimation:\", new_ber.ber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimate of the maximum achievable accuracy is one minus the BER estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The maximum achievable accuracy:\", 1 - new_ber.ber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results\n",
    "The maximum achievable accuracy on a dataset of 1 and not 1 (4, 9) is about 99.6%.\n",
    "This *does* meet our accuracy requirement.\n",
    "\n",
    "By using BER to check for feasibility early on, we were able to reformulate the problem such that it is feasible under our specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a classifier\n",
    "We can now attempt to build a classifier that achieves this level of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple CNN for classifying MNIST images.\n",
    "model = Sequential(\n",
    "    [\n",
    "        InputLayer(input_shape=(28, 28, 1)),\n",
    "        Conv2D(\n",
    "            64,\n",
    "            4,\n",
    "            strides=2,\n",
    "            padding=\"same\",\n",
    "            activation=relu,\n",
    "        ),\n",
    "        Conv2D(\n",
    "            128,\n",
    "            4,\n",
    "            strides=2,\n",
    "            padding=\"same\",\n",
    "            activation=relu,\n",
    "        ),\n",
    "        Conv2D(\n",
    "            512,\n",
    "            4,\n",
    "            strides=2,\n",
    "            padding=\"same\",\n",
    "            activation=relu,\n",
    "        ),\n",
    "        Flatten(),\n",
    "        Dense(2),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using a subset for training, we must also subset the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = np.where((test_labels == 1) | (test_labels == 4) | (test_labels == 9))\n",
    "test_images_subset = test_images[test_indices]\n",
    "test_labels_subset = test_labels[test_indices]\n",
    "test_labels_merged = test_labels_subset == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test the model\n",
    "Now we train and test the model on the modified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model hyperparameters\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Fitting a model may take a few minutes\n",
    "history = model.fit(\n",
    "    images_subset,\n",
    "    labels_merged,\n",
    "    epochs=90,\n",
    "    batch_size=16,\n",
    "    steps_per_epoch=1,\n",
    "    validation_data=(test_images_subset, test_labels_merged),\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights to avoid retraining\n",
    "model.save_weights(\"./checkpoints/trained_on_149_checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_images_subset, test_labels_merged, verbose=1)\n",
    "print(f\"The model accuracy: {accuracy*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Model Accuracy\")\n",
    "plt.plot(\n",
    "    range(60, 90), np.array(history.history[\"val_accuracy\"])[60:], label=\"Classifier\"\n",
    ")\n",
    "plt.hlines(\n",
    "    y=1 - new_ber.ber,\n",
    "    colors=[\"red\"],\n",
    "    xmin=60,\n",
    "    xmax=90,\n",
    "    label=\"1-BER\",\n",
    "    linestyles=\"dashed\",\n",
    ")\n",
    "plt.hlines(\n",
    "    y=0.99,\n",
    "    colors=[\"green\"],\n",
    "    xmin=60,\n",
    "    xmax=90,\n",
    "    label=\"Accuracy Requirement\",\n",
    "    linestyles=\"dashed\",\n",
    ")\n",
    "\n",
    "plt.xticks(range(60, 91, 10))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results\n",
    "The model achieves an accuracy of 99.14% accuracy, exceeding the requirement of 99%. \n",
    "\n",
    "The model accuracy does not quite approach the maximum achievable accuracy, meaning there are still improvements that can be made."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
