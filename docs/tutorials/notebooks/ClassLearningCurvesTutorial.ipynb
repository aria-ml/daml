{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Sufficiency Analysis for Classification Tutorial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Problem Statement_\n",
    "\n",
    "For machine learning tasks, often we would like to evaluate the performance of a model on a small, preliminary dataset. In situations where data collection is expensive, we would like to extrapolate hypothetical performance out to a larger dataset.\n",
    "\n",
    "DAML has introduced a method projecting performance via _sufficiency curves_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _When to use_\n",
    "\n",
    "The `Sufficiency` class should be used when you would like to extrapolate hypothetical performance. For example, if you have a small dataset, and would like to know if it is worthwhile to collect more data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _What you will need_\n",
    "\n",
    "1. A particular model architecture.\n",
    "2. Metric(s) that we would like to evaluate.\n",
    "3. A dataset of interest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Setting up_\n",
    "\n",
    "Let's import the required libraries needed to set up a minimal working example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "\n",
    "    !pip install -q daml[torch] torchmetrics torchvision\n",
    "    !export LC_ALL=\"en_US.UTF-8\"\n",
    "    !export LD_LIBRARY_PATH=\"/usr/lib64-nvidia\"\n",
    "    !export LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs\"\n",
    "    !ldconfig /usr/lib64-nvidia\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "!pip install -q tabulate\n",
    "\n",
    "import os\n",
    "\n",
    "from pytest import approx\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Sequence, cast\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms.v2 as v2\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "\n",
    "from daml.metrics import Sufficiency\n",
    "\n",
    "np.random.seed(0)\n",
    "np.set_printoptions(formatter={\"float\": lambda x: f\"{x:0.4f}\"})\n",
    "torch.manual_seed(0)\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./data\n",
       "    Split: Test"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.MNIST(\"./data\", train=True, download=True)\n",
    "datasets.MNIST(\"./data\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and define functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST data and create the training and test datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the mnist dataset and preview the images\n",
    "to_tensor = v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])\n",
    "train_ds = datasets.MNIST(\"./data\", train=True, download=True, transform=to_tensor)\n",
    "test_ds = datasets.MNIST(\"./data\", train=False, download=True, transform=to_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8, 3))\n",
    "\n",
    "for lbl in range(10):\n",
    "    i = (train_ds.targets == lbl).nonzero()[0][0]\n",
    "    img = train_ds.data[i]\n",
    "    ax = fig.add_subplot(2, 5, lbl + 1)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.imshow(img, cmap=\"gray_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this example, we will use subsets of the training (2000) and test (500) data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a subset of 2000 training images and 500 test images\n",
    "train_ds = Subset(train_ds, range(2000))\n",
    "test_ds = Subset(test_ds, range(500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the network architecture we will be using.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(6400, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model = torch.compile(Net().to(device))\n",
    "\n",
    "# Type cast the model back to Net as torch.compile returns a Unknown\n",
    "# Nothing internally changes from the cast; we are simply signaling the type\n",
    "model = cast(Net, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define our custom training and evaluation functions. Sufficiency requires that the evaluation function returns a dictionary of the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_train(model: nn.Module, dataset: Dataset, indices: Sequence[int]):\n",
    "    # Defined only for this testing scenario\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    epochs = 10\n",
    "\n",
    "    # Define the dataloader for training\n",
    "    dataloader = DataLoader(Subset(dataset, indices), batch_size=16)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in dataloader:\n",
    "            # Load data/images to device\n",
    "            X = torch.Tensor(batch[0]).to(device)\n",
    "            # Load targets/labels to device\n",
    "            y = torch.Tensor(batch[1]).to(device)\n",
    "            # Zero out gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward propagation\n",
    "            outputs = model(X)\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, y)\n",
    "            # Back prop\n",
    "            loss.backward()\n",
    "            # Update weights/parameters\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_eval(model: nn.Module, dataset: Dataset) -> Dict[str, float]:\n",
    "    metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "    result = 0\n",
    "\n",
    "    # Set model layers into evaluation mode\n",
    "    model.eval()\n",
    "    dataloader = DataLoader(dataset, batch_size=16)\n",
    "    # Tell PyTorch to not track gradients, greatly speeds up processing\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # Load data/images to device\n",
    "            X = torch.Tensor(batch[0]).to(device)\n",
    "            # Load targets/labels to device\n",
    "            y = torch.Tensor(batch[1]).to(device)\n",
    "            preds = model(X)\n",
    "            metric.update(preds, y)\n",
    "        result = metric.compute()\n",
    "    return {\"Accuracy\": result}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize sufficiency metric\n",
    "\n",
    "Attach the custom training and evaluation functions to the Sufficiency metric and define the number of models to train in parallel (stability), as well as the number of steps along the learning curve to evaluate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate sufficiency metric\n",
    "suff = Sufficiency(\n",
    "    model=model,\n",
    "    train_ds=train_ds,\n",
    "    test_ds=test_ds,\n",
    "    train_fn=custom_train,\n",
    "    eval_fn=custom_eval,\n",
    "    runs=5,\n",
    "    substeps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Sufficiency\n",
    "\n",
    "Now we can evaluate the metric to train the models and produce the learning curve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-21 23:10:11,120] torch._dynamo.convert_frame: [WARNING] WON'T CONVERT forward /tmp/ipykernel_992/1712871160.py line 11 \n",
      "[2024-05-21 23:10:11,120] torch._dynamo.convert_frame: [WARNING] due to: \n",
      "[2024-05-21 23:10:11,120] torch._dynamo.convert_frame: [WARNING] Traceback (most recent call last):\n",
      "[2024-05-21 23:10:11,120] torch._dynamo.convert_frame: [WARNING]   File \"/home/daml/.pyenv/versions/3.11.7/lib/python3.11/site-packages/torch/_inductor/scheduler.py\", line 1630, in create_backend\n",
      "[2024-05-21 23:10:11,120] torch._dynamo.convert_frame: [WARNING]     raise RuntimeError(\n",
      "[2024-05-21 23:10:11,120] torch._dynamo.convert_frame: [WARNING] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "[2024-05-21 23:10:11,120] torch._dynamo.convert_frame: [WARNING] RuntimeError: Found Quadro P2000 with Max-Q Design which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.1\n",
      "[2024-05-21 23:10:11,120] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-05-21 23:10:11,120] torch._dynamo.convert_frame: [WARNING] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "[2024-05-21 23:10:11,120] torch._dynamo.convert_frame: [WARNING] \n",
      "[2024-05-21 23:10:11,120] torch._dynamo.convert_frame: [WARNING] \n"
     ]
    }
   ],
   "source": [
    "# Train & test model\n",
    "output = suff.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out sufficiency output in a table format\n",
    "from tabulate import tabulate\n",
    "\n",
    "print(tabulate(output, headers=list(output.keys()), tablefmt=\"pretty\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out projected output values\n",
    "projection = Sufficiency.project(output, [1000, 2000, 4000], 100)\n",
    "print(tabulate(projection, list(projection.keys()), tablefmt=\"pretty\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "### TEST ASSERTION ###\n",
    "print(output[\"Accuracy\"][-1])\n",
    "print(projection[\"Accuracy\"][-1])\n",
    "assert output[\"Accuracy\"][-1] == approx(0.93, abs=0.03)\n",
    "assert projection[\"Accuracy\"][-1] == approx(0.95, abs=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the output using the convenience function\n",
    "_ = Sufficiency.plot(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Using this learning curve, we can project performance under much larger datasets (with the same model).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the learning curve to predict the amount of training samples required to achieve a desired accuracy.\n",
    "\n",
    "In the following cells, predict how many training images are\n",
    "needed to achieve model accuracies of 50%, 90%, and 98%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the array of desired accuracies\n",
    "desired_accuracies = np.array([0.5, 0.9, 0.98])\n",
    "\n",
    "# Evaluate the learning curve to infer the needed amount of training data\n",
    "num_needed_samples = Sufficiency.inv_project(desired_accuracies, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the amount of needed data needed to achieve the accuracies of interest\n",
    "for i, accuracy in enumerate(desired_accuracies):\n",
    "    print(\n",
    "        f\"To achieve {accuracy*100} % accuracy, {num_needed_samples[i]} training samples are needed.\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
