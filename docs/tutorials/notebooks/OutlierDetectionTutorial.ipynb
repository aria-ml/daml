{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Detection Tutorial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Problem Statement_\n",
    "\n",
    "For most computer vision tasks like **image classification** and **object detection**, outliers can provide insight into operational drift, or training problems. A way to identify these is through autoencoding reconstruction error.\n",
    "\n",
    "To help with this, DAML has introduced an outlier detector, based on _Alibi Detect_, that allows a user to identify outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _When to use_\n",
    "\n",
    "The `OD_AE` class should be used when you would like to find individual images in a dataset which are the most different form the others in the provided set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _What you will need_\n",
    "\n",
    "1. A PyTorch Dataset with your images returned first in \\_\\_getitem\\_\\_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Setting up_\n",
    "\n",
    "Let's import the required libraries needed to set up a minimal working example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %pip install -q daml[tensorflow]\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import os\n",
    "\n",
    "from pytest import approx\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from daml.metrics.outlier_detection import OD_AE, Threshold, ThresholdType\n",
    "\n",
    "tf.random.set_seed(108)\n",
    "tf.keras.utils.set_random_seed(408)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "We will use the tensorflow mnist dataset for this tutorial on outlier detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the mnist dataset from tensorflow datasets\n",
    "(images, ds_info) = tfds.load(\n",
    "    \"mnist\",\n",
    "    split=\"train\",\n",
    "    with_info=True,\n",
    ")  # type: ignore\n",
    "\n",
    "tfds.visualization.show_examples(images, ds_info)\n",
    "images = images.shuffle(images.cardinality())\n",
    "images = [i[\"image\"].numpy() for i in list(images.take(2000))]\n",
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the model\n",
    "\n",
    "Now, lets look at how to use DAML's outlier detection methods.  \n",
    "We will focus on a simple autoencoder network from our Alibi Detect provider\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the autoencoder-based outlier detector from alibi-detect\n",
    "metric = OD_AE()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Next we will train a model on the dataset.\n",
    "For better results, the epochs can be increased.\n",
    "We set the outlier threshold to detect the most extreme 1% of training data as outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the detector on the set of images\n",
    "metric.fit_dataset(\n",
    "    images=images,\n",
    "    epochs=20,\n",
    "    threshold=Threshold(100, ThresholdType.PERCENTAGE),\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for outliers\n",
    "\n",
    "We have trained our detector on a dataset of digits.  \n",
    "What happens when we give it corrupted images of digits (which we expect to be \"outliers\")?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_images, ds_info = tfds.load(\n",
    "    \"mnist_corrupted/translate\",\n",
    "    split=\"train\",\n",
    "    with_info=True,\n",
    ")  # type: ignore\n",
    "\n",
    "tfds.visualization.show_examples(corr_images, ds_info)\n",
    "corr_images = corr_images.shuffle(corr_images.cardinality())\n",
    "corr_images = [i[\"image\"].numpy() for i in list(corr_images.take(2000))]\n",
    "corr_images = np.array(corr_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we evaluate the two datasets using the trained model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_in = metric.evaluate(images)[\"is_outlier\"]\n",
    "print(f\"Original digits outliers: {np.mean(preds_in)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_corr = metric.evaluate(corr_images)[\"is_outlier\"]\n",
    "print(f\"Corrupted digits outliers: {np.mean(preds_corr)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "### TEST ASSERTION ###\n",
    "print(np.mean(preds_in))\n",
    "print(np.mean(preds_corr))\n",
    "assert np.mean(preds_in) == approx(0.01, abs=0.01)\n",
    "assert np.mean(preds_corr) == approx(0.8, abs=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "We identify most of the corrupted images as outliers!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
