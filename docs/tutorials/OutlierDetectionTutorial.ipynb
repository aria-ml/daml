{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection Tutorial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.datasets as tfds\n",
    "\n",
    "from daml.metrics.outlier_detection import AE\n",
    "\n",
    "tf.keras.utils.set_random_seed(408)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data\n",
    "We will use the tensorflow mnist dataset for this tutorial on outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in our images\n",
    "(images, labels), (test_images, test_labels) = tfds.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training samples: \", len(images))\n",
    "print(\"Image shape:\", images[0].shape)\n",
    "print(\"Label counts: \", np.unique(labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the model\n",
    "Now, lets look at how to use DAML's outlier detection methods.  \n",
    "We will focus on a simple autoencoder network from our Alibi Detect provider\n",
    "\n",
    "First, let's initialize our outlier detection model with the input image size of 28x28x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the autoencoder-based outlier detector from alibi-detect\n",
    "metric = AE()\n",
    "metric.initialize_detector((28, 28, 1))\n",
    "print(\"Outlier Detection Model:\", metric.detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial, we are going to trim down the data into only the labels 1, 4, and 9.  \n",
    "We will also only take 5000 of each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only 1, 4, and 9\n",
    "def get_subset(X, y, label, limit=5000):\n",
    "    indices = np.where(y == label)\n",
    "    X_sub = X[indices][:limit][..., np.newaxis]\n",
    "    y_sub = y[indices][:limit]\n",
    "    return X_sub, y_sub\n",
    "\n",
    "images_one, labels_one = get_subset(images, labels, 1)\n",
    "images_four, labels_four = get_subset(images, labels, 4)\n",
    "images_nine, labels_nine = get_subset(images, labels, 9)\n",
    "\n",
    "images_subset = np.concatenate([images_one, images_four, images_nine])\n",
    "labels_subset = np.concatenate([labels_one, labels_four, labels_nine])\n",
    "print(\"Image count:\", len(images_subset))\n",
    "print(\"Image shape:\", images_subset[0].shape)\n",
    "print(\"Label counts:\", np.unique(labels_subset, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model\n",
    "Next we will train a model on the dataset of 1, 4, and 9.\n",
    "For better results, the epochs can be increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the detector on the set of images\n",
    "metric.fit_dataset(dataset=images_subset, epochs=20, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test for outliers\n",
    "We have trained our detector on a dataset of digits 1, 4, 9.  \n",
    "What happens when we give it images of digit 0 (which we expect to be \"Outliers\")?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 28, 28, 1)\n",
      "(array([0], dtype=uint8), array([5000]))\n"
     ]
    }
   ],
   "source": [
    "# Only keep images with a label of 0\n",
    "indices_zero = np.where((labels == 0))\n",
    "images_zero = images[indices_zero][:5000][..., np.newaxis]\n",
    "labels_zero = labels[indices_zero][:5000]\n",
    "\n",
    "print(images_zero.shape)\n",
    "print(np.unique(labels_zero, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we evaluate the two datasets using the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digits 1, 4, and 9 outliers: 20.66%\n"
     ]
    }
   ],
   "source": [
    "preds_in = metric.evaluate(images_subset).is_outlier\n",
    "print(f\"Digits 1, 4, and 9 outliers: {np.mean(preds_in)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit 0 outliers:100.0%\n"
     ]
    }
   ],
   "source": [
    "preds_zeros = metric.evaluate(images_zero).is_outlier\n",
    "print(f\"Digit 0 outliers:{np.mean(preds_zeros)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results\n",
    "We identify all of the 0s as outliers!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
