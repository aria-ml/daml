{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection Tutorial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from daml.metrics.outlier_detection import AE\n",
    "\n",
    "tf.keras.utils.set_random_seed(408)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data\n",
    "We will use the tensorflow mnist dataset for this tutorial on outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the mnist dataset from tensorflow datasets\n",
    "tf.random.set_seed(108)\n",
    "(images, ds_info) = tfds.load(\n",
    "    \"mnist\",\n",
    "    split=\"train\",\n",
    "    with_info=True,\n",
    ")  # type: ignore\n",
    "tfds.visualization.show_examples(images,ds_info)\n",
    "images = images.shuffle(images.cardinality())\n",
    "images = [i[\"image\"].numpy() for i in list(images.take(5000))]\n",
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the model\n",
    "Now, lets look at how to use DAML's outlier detection methods.  \n",
    "We will focus on a simple autoencoder network from our Alibi Detect provider\n",
    "\n",
    "First, let's initialize our outlier detection model with the input image size of 28x28x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the autoencoder-based outlier detector from alibi-detect\n",
    "metric = AE()\n",
    "metric.initialize_detector((28, 28, 1))\n",
    "print(\"Outlier Detection Model:\", metric.detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model\n",
    "Next we will train a model on the dataset.\n",
    "For better results, the epochs can be increased.\n",
    "We set the outlier threshold to detect the most extreme 1% of training data as outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the detector on the set of images\n",
    "metric.fit_dataset(dataset=images, epochs=20, verbose=False)\n",
    "# Infer the threshold (given that none of these images are outliers)\n",
    "metric.detector.infer_threshold(images,threshold_perc= 100)\n",
    "metric.detector.threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test for outliers\n",
    "We have trained our detector on a dataset of digits.  \n",
    "What happens when we give it corrupted images of digits (which we expect to be \"Outliers\")?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_images,ds_info = tfds.load(\"mnist_corrupted/translate\",\n",
    "split=\"train\",\n",
    "with_info=True,\n",
    ")  # type: ignore  # type: ignore\n",
    "tfds.visualization.show_examples(corr_images,ds_info)\n",
    "corr_images = corr_images.shuffle(corr_images.cardinality())\n",
    "corr_images = [i[\"image\"].numpy() for i in list(corr_images.take(5000))]\n",
    "corr_images = np.array(corr_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we evaluate the two datasets using the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_in = metric.evaluate(images).is_outlier\n",
    "print(f\"Original digits outliers: {np.mean(preds_in)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_corr = metric.evaluate(corr_images).is_outlier\n",
    "print(f\"Corrupted digits outliers:{np.mean(preds_corr)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results\n",
    "We identify (nearly) all of the corrupted images as outliers!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
