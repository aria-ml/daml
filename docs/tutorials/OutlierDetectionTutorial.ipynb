{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection Tutorial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from daml.datasets import DamlDataset\n",
    "from daml.metrics.outlier_detection import AE, Threshold, ThresholdType\n",
    "\n",
    "tf.random.set_seed(108)\n",
    "tf.keras.utils.set_random_seed(408)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data\n",
    "We will use the tensorflow mnist dataset for this tutorial on outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the mnist dataset from tensorflow datasets\n",
    "(images, ds_info) = tfds.load(\n",
    "    \"mnist\",\n",
    "    split=\"train\",\n",
    "    with_info=True,\n",
    ")  # type: ignore\n",
    "\n",
    "tfds.visualization.show_examples(images,ds_info)\n",
    "images = images.shuffle(images.cardinality())\n",
    "images = [i[\"image\"].numpy() for i in list(images.take(3000))]\n",
    "dataset = DamlDataset(np.array(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the model\n",
    "Now, lets look at how to use DAML's outlier detection methods.  \n",
    "We will focus on a simple autoencoder network from our Alibi Detect provider\n",
    "\n",
    "First, let's initialize our outlier detection model with the input image size of 28x28x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the autoencoder-based outlier detector from alibi-detect\n",
    "metric = AE()\n",
    "metric.initialize_detector(dataset.images[0].shape)\n",
    "print(\"Outlier Detection Model:\", metric.detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model\n",
    "Next we will train a model on the dataset.\n",
    "For better results, the epochs can be increased.\n",
    "We set the outlier threshold to detect the most extreme 1% of training data as outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the detector on the set of images\n",
    "metric.fit_dataset(\n",
    "    dataset=dataset,\n",
    "    epochs=12,\n",
    "    threshold=Threshold(100, ThresholdType.PERCENTAGE),\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test for outliers\n",
    "We have trained our detector on a dataset of digits.  \n",
    "What happens when we give it corrupted images of digits (which we expect to be \"outliers\")?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_images,ds_info = tfds.load(\"mnist_corrupted/translate\",\n",
    "    split=\"train\",\n",
    "    with_info=True,\n",
    ")  # type: ignore\n",
    "\n",
    "tfds.visualization.show_examples(corr_images,ds_info)\n",
    "corr_images = corr_images.shuffle(corr_images.cardinality())\n",
    "corr_images = [i[\"image\"].numpy() for i in list(corr_images.take(3000))]\n",
    "corr_dataset = DamlDataset(np.array(corr_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we evaluate the two datasets using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_in = metric.evaluate(dataset).is_outlier\n",
    "print(f\"Original digits outliers: {np.mean(preds_in)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_corr = metric.evaluate(corr_dataset).is_outlier\n",
    "print(f\"Corrupted digits outliers: {np.mean(preds_corr)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results\n",
    "We identify a significant number of the corrupted images as outliers!  \n",
    "Additional epochs when fitting the dataset will further improve the performance of outlier detection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
