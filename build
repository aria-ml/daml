#!/bin/bash -e
set -o pipefail

function showHelp() {
cat << EOF
Usage:
  build [options] <tasks(s)> <python version(s)>

Options:
      --build-base  only build base dependency images
      --build-task  only build task images
  -h, --help        display this help information
  -q, --quiet       do not print output to console during container execution
      --gpu         enable gpu support on task execution
      --push        push all built images to repository

Default:
  run unit tests and type check for 3.9-3.11 as well as lint and docs

Python Versions:
  3.9-3.11 are supported

Tasks:
  unit    run unit tests
  type    run typecheck
  lint    run static code analysis
  deps    run minimum dependency tests
  docs    generate documentation
  qdocs   generate documentation using cached notebooks
  doctest run documentation tests

Note:
  docs, qdocs and doctest are always performed on python 3.11
EOF
exit $1
}

options=$(getopt -l "help,quiet,gpu,build-base,build-task,push" -o "hq" -n "build" -- "$@")
eval set -- "$options"
while true; do
    case "$1" in
        -h|--help)       showHelp;;
        -q|--quiet)      export quiet=1; export verbosity="--quiet";;
        --gpu)           export gpuflag="--gpus all";;
        --build-base)    build_base=1;;
        --build-task)    build_task=1;;
        --push)          if [[ ! $CI ]]; then echo "Only CI pipelines should be pushing."; exit 1; else export push_to_repo=1; fi;;
        --)              shift; break;;
    esac
    shift
done

if [[ -f .settings ]]; then
    if [[ $(cat .settings | grep save-build-images) ]]; then
        export save_build_images="true"
    fi
fi

# declare lookup maps
declare -A supported_pvers=([3.9]=1 [3.10]=1 [3.11]=1)
declare -A supported_tasks=([unit]=1 [type]=1 [lint]=1 [deps]=1)
declare -A supported_docs=([docs]=1 [qdocs]=1 [doctest]=1)

# generate python and task lists
declare -A pvers; declare -A tasks;
count=0; c_pvers=0; c_tasks=0; c_docs=0;

# validate args
for arg do
    if [[ $arg == -* ]]; then continue; fi
    if [[ ${supported_pvers["$arg"]} ]]; then pvers[$arg]=1; ((++c_pvers)); fi
    if [[ ${supported_tasks["$arg"]} ]]; then tasks[$arg]=1; ((++c_tasks)); fi
    if [[ ${supported_docs["$arg"]} ]]; then tasks[$arg]=1; ((++c_docs)); fi
    ((++count))
done

# show help if arg count mismatch
if [[ $((c_pvers + c_tasks + c_docs)) != $count ]]; then showHelp 1; fi

# set all python versions if none specified
if [[ $count == 0 || ($c_pvers == 0 && $c_tasks != 0) ]]; then pvers=([3.9]=1 [3.10]=1 [3.11]=1); fi

# for build_task we should run these specific tasks
if [[ $build_task ]]; then tasks=([unit]=1 [type]=1 [lint]=1 [deps]=1); fi

# set defaults if not specified
if [[ ! $build_base && ! $build_task ]]; then
    if [[ $count == 0 || ($c_tasks == 0 && $c_pvers != 0) ]]; then tasks[unit]=1; tasks[type]=1; fi
fi

# generate "task-python_version" jobs
declare -A jobs;
for task in "${!tasks[@]}"; do
    case "$task" in
        docs|qdocs|doctest) jobs["$task-3.11"]=1;;
        *) for python_version in "${!pvers[@]}"; do jobs["$task-$python_version"]=1; done;;
    esac
done

export builder_name="daml"
if [[ -z $(docker builder ls --format '{{.Name}}' | grep $builder_name) ]]; then
    echo "builder instance named $builder_name doesn't exist, creating it now..."
    docker builder create \
        --driver docker-container \
        --bootstrap \
        --name $builder_name
fi

function post_build_cleanup() {
    tag=$1
    container_name=$2

    if [[ $(docker container ls --all --filter name=$container_name) ]]; then
        docker container rm --force $container_name &> /dev/null
    fi

    if [[ -z $save_build_images && $(docker image ls --filter reference=$tag) ]]; then
        docker image rm --force $tag &> /dev/null
    fi
}

function build_image() {
    target=$1
    python_version=$2
    no_cache_layers=${@:3}

    # create cache array
    cache=("${registry}/cache:pyenv-${python_version}")
    if [[ $target != pyenv ]]; then
        cache+=("${registry}/cache:${deps_hash}-base-${python_version}")
        if [[ $target != base ]]; then
            cache+=("${registry}/cache:${deps_hash}-${target}-${python_version}")
        fi
    fi

    # set cache_from and cache_to args
    cache_from_arg=$(echo ${cache[*]} | xargs -n1 sh -c 'echo --cache-from type=registry,ref=$0')
    if [[ $push_to_repo ]]; then
        # Writing to the cache means that you must be able to push to the registry, therefore
        # don't want to force users to login to the registry just to build.
        cache_to_arg="--cache-to type=registry,mode=max,image-manifest=true,ref=${cache[-1]}"
    else
        cache_to_arg=""
    fi

    # set no_cache_filter_arg
    if [[ $no_cache_layers ]]; then
        no_cache_filter_arg="--no-cache-filter $(tr ' ' ',' <<< $no_cache_layers)"
    fi

    # build image_tag only for pyenv (if not exist) or for task (non pyenv, base) images
    if [[ $target == pyenv && ! $(docker manifest inspect "${registry}/pyenv:${python_version}" 2> /dev/null) ]]; then
        image_tag="${registry}/pyenv:${python_version}"
    elif [[ $target != pyenv && $target != base ]]; then
        image_tag="${registry}/${image}:${tag_prefix}${deps_hash}-${target}-${python_version}"
    else
        image_tag=""
    fi

    # build output_arg to image only if image_tag is created
    if [[ $image_tag ]]; then
        output_arg="--output type=image,name=${image_tag}"
        if [[ $push_to_repo ]]; then
            output_arg+=",push=true"
        fi
        if [[ $target != pyenv && ($save_build_images || -z $push_to_repo) ]]; then
            # By default the docker-container driver doesn't load images to the
            # local docker images store, these args will cause it to do so.
            load_arg="--tag ${image_tag} --load"
        fi
    else
        output_arg="--output type=cacheonly"
    fi

    docker_build_cmd="docker buildx build $verbosity \
        $load_arg \
        --builder $builder_name \
        --build-arg python_version=$python_version \
        $no_cache_filter_arg \
        $cache_from_arg \
        $cache_to_arg \
        $output_arg \
        --target $target \
        ."

    echo "Building $target for $python_version"
    echo "========================================"
    echo $docker_build_cmd
    time $docker_build_cmd
    echo "========================================"
    echo "Finished $target for $python_version"
}

function build_and_run() {
    IFS=- read -r task python_version <<< $1

    container_name="run-${task}-${python_version}"
    if [[ $CI_PIPELINE_ID ]]; then
        container_name="${container_name}-${CI_PIPELINE_ID}"
    fi

    # If the image was pushed, then we need to be sure to pull the updated image
    if [[ $push_to_repo ]]; then
        pull_arg="--pull always"
    fi

    image_tag="${registry}/${image}:${tag_prefix}${deps_hash}-${task}-${python_version}"
    trap "post_build_cleanup $image_tag $container_name" EXIT

    # NOTE: If you ./build --push at the same time as a pipeline in the same
    # branch that is running you can potentially overwrite a results image that
    # will be read from in that pipeline run.
    if [[ ! $(docker manifest inspect $image_tag 2> /dev/null) ]]; then
        build_image $task $python_version
    fi

    echo "======================================================================"
    echo "Output from ${container_name}"
    echo "----------------"
    set +e
    docker run --interactive $pull_arg --name $container_name $gpuflag $image_tag
    exitcode=$?
    set -e
    echo "----------------"
    echo "${container_name} exit code: ${exitcode}"
    echo "======================================================================"

    mkdir -p output
    docker cp $container_name:/daml/output/ .

    if [[ $exitcode != 0 ]]; then
        exit $exitcode
    fi
}

export -f post_build_cleanup
export -f build_image
export -f build_and_run

# In CI pipelines use commit branch name or merge request source branch name
# These are mutually exclusive when set
# https://docs.gitlab.com/ee/ci/variables/predefined_variables.html
if [[ $CI ]]; then
    branch_name=$CI_COMMIT_BRANCH$CI_MERGE_REQUEST_SOURCE_BRANCH_NAME
    main_branch=$CI_DEFAULT_BRANCH
else
    branch_name=$(git rev-parse --abbrev-ref HEAD)
    main_branch="main"
fi

# Set components used for image and tag and are built in general with:
# ${registry}/${image}:${tag_prefix}${deps_hash}-${task}-${python_version}
export registry="harbor.jatic.net/daml"
if [[ $branch_name == $main_branch ]]; then
    export image="main"
else
    export image="dev"
    export tag_prefix="${branch_name/[^a-zA-Z0-9]/-}-"
fi
export deps_hash=$((cat environment/requirements.txt && cat environment/requirements-dev.txt) | sha256sum | cut -c 1-8)

START=$(date +%s)

for python_version in ${!pvers[@]}; do
    # In the CI pipeline, build_base and build_task are staged separately to allow docs to kick
    # off quicker. These checks allow us to run either base or task exclusively. Removing this
    # optimization would mean we could just combine both and remove the conditional checks.
    if [[ ! $CI || $build_base ]]; then
        build_image pyenv $python_version
        build_image base $python_version
    fi
    if [[ ! $CI || $build_task ]]; then
        pids=()
        trap "for pid in ${pids[@]}; do kill $pid; done; exit 1" INT
        for task in ${!tasks[@]}; do
            (verbosity="--quiet" build_image $task $python_version) &
            pids+=($!)
        done
        for pid in ${pids[@]}; do
            wait $pid || exit_code=$?
        done
        trap - INT
    fi
done

if [[ $build_base || $build_task ]]; then
    exit $exit_code
fi

END=$(date +%s)
DIFF=$(( $END - $START ))
echo "------"
echo "Image build preparation completed in $DIFF seconds"
echo "------"

if [[ ! $quiet ]]; then
    keep_order="--keep-order"
fi

# execute jobs
echo "Running ${!jobs[@]}..."
case ${#jobs[@]} in
    0)  showHelp 1;;
    1)  build_and_run ${!jobs[@]};;
    *)  parallel $keep_order --lb --tag 'set -o pipefail; build_and_run' ::: ${!jobs[@]};;
esac
