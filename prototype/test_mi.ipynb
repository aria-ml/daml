{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from fmow_utils import extrinsic_factors_fmow\n",
    "from matplotlib.patches import Rectangle\n",
    "from metadata import MetadataBias, str2int, validate_dict\n",
    "\n",
    "demo_classes = [\n",
    "    \"airport\",\n",
    "    \"border_checkpoint\",\n",
    "    \"dam\",\n",
    "    \"factory_or_powerplant\",\n",
    "    \"hospital\",\n",
    "    \"military_facility\",\n",
    "    \"nuclear_powerplant\",\n",
    "    \"oil_or_gas_facility\",\n",
    "    \"place_of_worship\",\n",
    "    \"port\",\n",
    "    \"prison\",\n",
    "    \"stadium\",\n",
    "    \"electric_substation\",\n",
    "    \"road_bridge\",\n",
    "]\n",
    "\n",
    "split_name = \"dev\"\n",
    "# country_code = \"RUS\"\n",
    "\n",
    "tvt_splits = [\"train\", \"val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for split in tvt_splits:\n",
    "    dfs.append(pd.read_csv(f\"splits/{split_name}_{split}.csv\"))\n",
    "\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load precomputed table of FMOW labels and metadata\n",
    "# df = pd.read_pickle(\"../trainval_labels_factors.pkl\").reset_index(drop=True)\n",
    "# df[\"class\"] = df[\"class\"].astype(\"category\")\n",
    "# df[\"split\"] = df.split.astype(\"category\")\n",
    "\n",
    "# df = df[df.country_code == \"USA\"]\n",
    "# df = df[df[\"class\"].isin(demo_classes)]\n",
    "# # xywh\n",
    "# boxes = get_fmow_boxes(df)\n",
    "# img_sizes = np.column_stack((df.img_width.to_numpy(), df.img_height.to_numpy()))\n",
    "\n",
    "# # quick check for missing classes if we filter down to USA\n",
    "# us_classes = list(df[\"class\"].unique())\n",
    "# missing = [c for c in demo_classes if c not in us_classes]\n",
    "# missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather intrinsic factors (dataset agnostic)\n",
    "# int_fmow, int_categorical = intrinsic_factors_xywh(boxes, img_sizes)\n",
    "\n",
    "# gather extrinsic factors (custom to FMOW)\n",
    "ext_fmow, ext_categorical = extrinsic_factors_fmow(df)\n",
    "\n",
    "# class labels\n",
    "cls_fmow = {\"class\": df[\"class\"].to_numpy()}\n",
    "cls_categorical = {\"class\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine factors\n",
    "factors = {**cls_fmow, **ext_fmow}\n",
    "is_categorical = {**cls_categorical, **ext_categorical}\n",
    "# match insertion order --- done in MetadataBias class as well\n",
    "is_categorical = {key: is_categorical[key] for key in factors}\n",
    "\n",
    "# map non-numeric variables to integers\n",
    "orig_class = factors[\"class\"]\n",
    "factors = str2int(factors)\n",
    "\n",
    "# make sure we have a categorical label for each factor\n",
    "assert all(k in is_categorical for k in factors)\n",
    "# make sure each factor has the same number of entries\n",
    "validate_dict(factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = MetadataBias(factors, is_categorical)\n",
    "\n",
    "# mi_joint = md.compute_mutual_information(num_neighbors=5)\n",
    "# mi_onehot = md.mutual_information_by_class(num_neighbors=5)\n",
    "\n",
    "# factors.keys() == is_categorical.keys()\n",
    "# zip(md.names, )\n",
    "# list(md.is_categorical.keys())\n",
    "# np.unique(md.data[:, md.names.index(\"cloud_cover\")]).shape\n",
    "# print(md.is_categorical)\n",
    "# md.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_onehot = md.mutual_information_by_class(class_var=\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MI with one-hot classes\n",
    "classes, _ = np.unique(orig_class, return_inverse=True)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(24, 8))\n",
    "# cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns_plot = sns.heatmap(\n",
    "    mi_onehot,\n",
    "    cmap=\"viridis\",\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\": 0.5, \"label\": \"Normalized Mutual Information\"},\n",
    "    xticklabels=md.names[1:],\n",
    "    yticklabels=classes,\n",
    "    annot=True,\n",
    ")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.tight_layout(pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MI between factors (joint class variable)\n",
    "mi = md.compute_mutual_information()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 8))\n",
    "# mask out lower triangular portion\n",
    "mask = np.zeros_like(mi, dtype=np.bool_)\n",
    "mask[np.tril_indices_from(mask)] = True\n",
    "mask[np.diag_indices_from(mask)] = True\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns_plot = sns.heatmap(\n",
    "    np.minimum(mi[:, 1:], 1),\n",
    "    mask=mask[:, 1:],\n",
    "    cmap=\"viridis\",\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\": 0.5, \"label\": \"Normalized Mutual Information\"},\n",
    "    xticklabels=md.names[1:],\n",
    "    yticklabels=md.names[:-1],\n",
    "    annot=True,\n",
    ")\n",
    "# highlight correlation with class\n",
    "ax.add_patch(Rectangle((0, 0), mi.shape[0], 1, fill=False, edgecolor=\"k\", lw=4))\n",
    "plt.tight_layout(pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  demo data\n",
    "balance_data = {\n",
    "    \"mutual_information\": mi.tolist(),\n",
    "    \"factors\": md.names,\n",
    "}\n",
    "\n",
    "balance_classwise_data = {\n",
    "    \"mutual_information\": mi_onehot.tolist(),\n",
    "    \"classes\": classes.tolist(),\n",
    "    \"factors\": md.names,\n",
    "}\n",
    "\n",
    "tvt_str = \"\".join(tvt_splits)\n",
    "\n",
    "with open(f\"{split_name}_{tvt_str}_balance_data.json\", \"w\") as fp:\n",
    "    json.dump(balance_data, fp)\n",
    "with open(f\"{split_name}_{tvt_str}_balance_classwise.json\", \"w\") as fp:\n",
    "    json.dump(balance_classwise_data, fp)\n",
    "\n",
    "# balance_rollup = np.sum(np.array(balance_data[\"mutual_information\"])[0, 1:] > 0.5)\n",
    "# print(balance_rollup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_classwise_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
