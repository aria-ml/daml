workflow:
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      changes:
        - "CHANGELOG.md"
      when: never
    - if: $CI_COMMIT_TAG
      when: never
    - if: $DAML_NIGHTLY
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH

default:
  tags:
    - aria

stages:
  - info
  - prune
  - test
  - release

.on_nightly:
  rules:
    - if: $DAML_NIGHTLY
      when: on_success
    - when: never

.on_default:
  rules:
    - if: $DAML_NIGHTLY
      when: never
    - when: on_success

.on_release:
  stage: release
  environment:
    name: production
  rules:
    - if: $DAML_NIGHTLY
      when: never
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      changes:
        - src/**/*
        - pyproject.toml

image: python:$PYTHON_LATEST_SUPPORTED_VERSION

variables:
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"
  PYTHON_LATEST_SUPPORTED_VERSION: "3.11"
  DOCKER_DRIVER: overlay2

cache:
  paths:
    - .cache/pip
    - venv/

before_script:
  - if [[ ! $(which bash) ]]; then apk add --no-cache bash; fi

info:
  stage: info
  image: docker:20.10-git
  parallel:
    matrix:
      - TAG: ["aria", "GPU1", "GPU2"]
  tags:
    - ${TAG}
  script:
    - docker version
    - docker info
    - docker system df
    - docker container ls --all
    - docker image ls --all
    - docker volume ls
  allow_failure: true

# Clear unused docker data on nightly basis
prune:
  extends: .on_nightly
  stage: prune
  image: docker:20.10-git
  parallel:
    matrix:
      - TAG: ["aria", "GPU1", "GPU2"]
  tags:
    - ${TAG}
  script:
    - docker system df --verbose
    - docker builder prune --force --keep-storage 50GB
    - docker image prune --force
    - docker volume prune --force
    - docker system df
  allow_failure: true

build:
  image: docker:20.10-git
  script:
    - ./build --build-only

.test:
  stage: test
  image: docker:20.10-git
  needs:
    - job: build
      optional: true
  parallel:
    matrix:
      - PYTHON_VERSIONS: ["3.8", "3.9", "3.10", "3.11"]
  script:
    - ./build ${PYTHON_VERSIONS} ${TASK}
  artifacts:
    reports:
      junit: output/junit.${TASK}.${PYTHON_VERSIONS}.xml
    paths:
      - output/junit.${TASK}.${PYTHON_VERSIONS}.xml
      - output/.coverage.${TASK}.${PYTHON_VERSIONS}
      - output/htmlcov.${TASK}.${PYTHON_VERSIONS}

test:
  extends:
    - .test
    - .on_default
  variables:
    TASK: unit

functional:
  extends:
    - .test
    - .on_nightly
  variables:
    TASK: func

coverage:
  stage: test
  needs:
    - job: test
      optional: true
      artifacts: true
    - job: functional
      optional: true
      artifacts: true
  before_script:
    - pip install coverage
  script:
    # TODO: Move coverage report generation in to build script (and/or resolve issue with using symlinks instead of a full recursive copy)
    - cp --recursive $(pwd) /daml
    - coverage combine ./output
    - coverage report -m --skip-empty
    - coverage xml --skip-empty
    - coverage html --skip-empty
  coverage: "/(?i)total.*? (100(?:\\.0+)?\\%|[1-9]?\\d(?:\\.\\d+)?\\%)$/"
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml
    paths:
      - coverage.xml
      - htmlcov/

linting:
  extends: .on_default
  image: docker:20.10-git
  needs:
    - job: build
      optional: true
  script:
    - ./build lint

typecheck:
  extends: .on_default
  image: docker:20.10-git
  needs:
    - job: build
      optional: true
  parallel:
    matrix:
      - PYTHON_VERSIONS: ["3.8", "3.9", "3.10", "3.11"]
  script:
    - ./build ${PYTHON_VERSIONS} type

generate shipped dependencies:
  image: docker:20.10-git
  needs:
    - job: build
      optional: true
  script:
    - ./build deps
  artifacts:
    paths:
      - output/requirements.txt
  rules:
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'

sphinx:
  extends: .on_nightly
  stage: test
  image: docker:20.10-git
  needs:
    - job: build
      optional: true
  #  tags: [GPU]
  script:
    - ./build docs # --gpu
  artifacts:
    paths:
      - output/docs/html/

pages:
  extends: .on_nightly
  needs:
    - job: sphinx
      artifacts: true
    - job: coverage
      artifacts: true
  stage: release
  script:
    - mv output/docs/html/ ./public/
    - mv htmlcov/ ./public/coverage/
  artifacts:
    paths:
      - public

tag:
  extends: .on_release
  script:
    - ./.gitlab/auto_tag.sh

publish:
  extends: .on_release
  needs:
    - tag
  image: python:$PYTHON_LATEST_SUPPORTED_VERSION
  script:
    - pip install build twine --upgrade
    - twine --version
    - python -m build
    - twine upload --repository-url ${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/packages/pypi -u gitlab-ci-token -p $DAML_BUILD_PAT dist/*

changelog:
  extends: .on_release
  needs:
    - publish
  script:
    - pip install requests
    - python .gitlab/update_changelog.py

include:
  - template: Security/SAST.gitlab-ci.yml
  - template: Security/Dependency-Scanning.gitlab-ci.yml
  - template: Security/Secret-Detection.gitlab-ci.yml

secret_detection:
  rules:
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'

gemnasium-python-dependency_scanning:
  needs:
    - job: generate shipped dependencies
      artifacts: true
  # Both `needs` and `dependencies` are used due to a quirk of gitlab.
  # `gemnasium-python-dependency_scanning` specifies an empty list of
  # dependencies, which means that unless you explicitly add the dependency,
  # all artifacts will be filtered out and removed from this job.
  dependencies:
    - generate shipped dependencies
  variables:
    # This seems like it *should* resolve the dev dependencies problem, but
    # it doesn't seem to work, probably due to the change in poetry 1.2.0 that
    # removed the "dev-dependencies" section in favor of naming a dependency group "dev"
    # (https://python-poetry.org/docs/managing-dependencies/#dependency-groups).
    # Leaving it configured for visibility, in case it gets fixed in the future.
    DS_INCLUDE_DEV_DEPENDENCIES: "false"
    DS_EXCLUDED_PATHS: "poetry.lock"
  rules:
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'

semgrep-sast:
  rules:
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
